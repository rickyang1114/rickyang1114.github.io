---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm a Ph.D. student at [VAI group](https://zjuvag.org/) of State Key Lab of CAD&CG, Zhejiang University. I'm currently insterested in Trustworthy AI and LLMs.

# ğŸ”¥ News
- *2024.05*: &nbsp;ğŸ‰ğŸ‰ One paper gets accepted by ACL 2024

# ğŸ“ Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2024</div><img src='images/sdft.png' alt="SDFT image" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning](https://arxiv.org/pdf/2402.13669) \| [Code](https://github.com/sail-sg/sdft) 

**Zhaorui Yang**, Qian Liu, Tianyu Pang, Haozhe Feng, Han Wang, Minfeng Zhu, Wei Chen

- In this work, we propose a novel fine-tuning approach to mitigate the catastrophic forgetting during the fine-tuning of language models.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2304.06627</div><img src='images/cosda_setting.png' alt="CoSDA setting image" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CoSDA: Continual Source-Free Domain Adaptation](https://arxiv.org/pdf/2304.06627) \| [Code](https://github.com/FengHZ/CoSDA) 

Haozhe Feng\*, **Zhaorui Yang\***, Hesun Chen\*, Tianyu Pang, Chao Du, Minfeng Zhu, Wei Chen, Shuicheng Yan

- In this work, we investigate the mechanism of catastrophic forgetting of previous Source-Free Domain Adaptation (SFDA) approaches. Motivated by the findings, we propose CoSDA which outperforms SOTA approaches in continuous adaptation.
</div>
</div>

> The symbol \* represents equal contribution.

# ğŸ– Honors and Awards
- *2022.12* China National Scholarship.
- *2021.12* China National Scholarship.

# ğŸ“– Educations
- *2023.09 - now* <br> Ph.D. student in Software Engineering at State Key Lab of CAD&CG, Zhejiang University.
- *2019.09 - 2023.06* <br> B.E. in Software Engineering, Xi'an Jiaotong University.

# ğŸ’» Internships
None yet.